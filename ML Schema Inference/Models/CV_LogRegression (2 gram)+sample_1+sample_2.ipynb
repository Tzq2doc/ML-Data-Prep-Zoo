{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from keras.utils import to_categorical\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WITH STANDARDIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2714: DtypeWarning: Columns (2,5,10,11,12,13,14,15,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#read csv\n",
    "dict_label = {'Usable directly numeric':0, 'Usable with extraction':1, 'Usable with Extration': 1, 'Usable with extraction ':1, 'Usable directly categorical':2, 'Unusable':3, 'Context_specific':4, 'Usable directly categorical ':2}\n",
    "data = pd.read_csv('data_for_ML_num.csv')\n",
    "\n",
    "data['y_act'] = [dict_label[i] for i in data['y_act']]\n",
    "y = data.loc[:,['y_act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={'Num of nans': 'Num_of_nans', 'num of dist_val': 'num_of_dist_val'})\n",
    "\n",
    "data['Num_of_nans'] = [float(data['Num_of_nans'][i])/float(data['Total_val'][i]) for i in data.index]\n",
    "data['num_of_dist_val'] = [float(data['num_of_dist_val'][i])/float(data['Total_val'][i]) for i in data.index]\n",
    "\n",
    "data1 = data[['Num_of_nans', 'max_val', 'mean', 'min_val', 'num_of_dist_val','std_dev','castability','extractability', 'len_val']]\n",
    "data1 = data1.fillna(0)\n",
    "\n",
    "data1 = data1.rename(columns={'mean': 'scaled_mean', 'min_val': 'scaled_min_val', 'max_val': 'scaled_max_val','std_dev': 'scaled_std_dev'})\n",
    "data1.loc[data1['scaled_min_val'] > 10000, 'scaled_min_val'] = 10000\n",
    "data1.loc[data1['scaled_min_val'] < -10000, 'scaled_min_val'] = -10000\n",
    "data1.loc[data1['scaled_max_val'] > 10000, 'scaled_max_val'] = 10000\n",
    "data1.loc[data1['scaled_max_val'] < -10000, 'scaled_max_val'] = -10000\n",
    "data1.loc[data1['scaled_mean'] > 10000, 'scaled_mean'] = 10000\n",
    "data1.loc[data1['scaled_mean'] < -10000, 'scaled_mean'] = -10000\n",
    "data1.loc[data1['scaled_std_dev'] > 10000, 'scaled_std_dev'] = 10000\n",
    "data1.loc[data1['scaled_std_dev'] < -10000, 'scaled_std_dev'] = -10000\n",
    "column_names_to_normalize = ['scaled_max_val', 'scaled_mean', 'scaled_min_val','scaled_std_dev']\n",
    "x = data1[column_names_to_normalize].values\n",
    "x = np.nan_to_num(x)\n",
    "x_scaled = StandardScaler().fit_transform(x)\n",
    "df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = data1.index)\n",
    "data1[column_names_to_normalize] = df_temp\n",
    "\n",
    "data1.Num_of_nans = data1.Num_of_nans.astype(float)\n",
    "data1.num_of_dist_val = data1.num_of_dist_val.astype(float)\n",
    "data1.castability = data1.castability.astype(float)\n",
    "data1.extractability = data1.extractability.astype(float)\n",
    "y.y_act = y.y_act.astype(float)\n",
    "\n",
    "import enchant\n",
    "data1.to_csv('before.csv')\n",
    "f = open('current.txt','w')\n",
    "d = enchant.Dict(\"en_US\")\n",
    "\n",
    "for i in data.index:\n",
    "    ival = data.at[i,'Attribute_name']\n",
    "    if ival != 'id' and d.check(ival):\n",
    "        print >> f,ival\n",
    "        print >> f,y.at[i,'y_act']\n",
    "        data1.at[i,'dictionary_item'] = 1\n",
    "    else:\n",
    "        data1.at[i,'dictionary_item'] = 0\n",
    "\n",
    "data1.to_csv('after.csv')\n",
    "f.close()\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# print(data1.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1927\n"
     ]
    }
   ],
   "source": [
    "arr = data['Attribute_name'].values\n",
    "data = data.fillna(0)\n",
    "arr1 = data['sample_1'].values\n",
    "arr1 = [str(x) for x in arr1]\n",
    "arr2 = data['sample_2'].values\n",
    "arr2 = [str(x) for x in arr2]\n",
    "\n",
    "# print(arr)\n",
    "# print(arr1)\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2),analyzer='char')\n",
    "X = vectorizer.fit_transform(arr)\n",
    "X1 = vectorizer.fit_transform(arr1)\n",
    "X2 = vectorizer.fit_transform(arr2)\n",
    "\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "\n",
    "data1.to_csv('before.csv')\n",
    "tempdf = pd.DataFrame(X.toarray())\n",
    "tempdf1 = pd.DataFrame(X1.toarray())\n",
    "tempdf2 = pd.DataFrame(X2.toarray())\n",
    "\n",
    "data2 = pd.concat([data1,tempdf,tempdf1,tempdf2], axis=1, sort=False)\n",
    "data2.to_csv('after.csv')\n",
    "\n",
    "\n",
    "X_train, X_test,y_train,y_test = train_test_split(data2,y, test_size=0.2,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(new_data)\n",
    "# print(df)\n",
    "# print(np.where(x >= np.finfo(np.float64).max))\n",
    "# print(np.finfo(np.float64).max)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.to_csv('xtrain.csv')\n",
    "# y_train.to_csv('ytrain.csv')\n",
    "# X_test.to_csv('xtest.csv')\n",
    "# y_test.to_csv('ytest.csv')\n",
    "# data.to_csv('abc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9349662162162162\n",
      "0.8425675675675676\n",
      "0.8438681793625068\n",
      "0.9347972972972973\n",
      "0.8243243243243243\n",
      "0.839546191247974\n",
      "0.9373310810810811\n",
      "0.8135135135135135\n",
      "0.8438681793625068\n",
      "0.9364864864864865\n",
      "0.8391891891891892\n",
      "0.8411669367909238\n",
      "0.9368243243243243\n",
      "0.8344594594594594\n",
      "0.8390059427336575\n"
     ]
    }
   ],
   "source": [
    "# logisticRegr = LogisticRegression(penalty='l2',multi_class='multinomial', solver='lbfgs',C = 100,max_iter=200)\n",
    "# logisticRegr = LogisticRegressionCV(cv=5,penalty='l2',multi_class='multinomial', solver='lbfgs',Cs = 1,max_iter=200)\n",
    "# X_train_train, X_test_train,y_train_train,y_test_train = train_test_split(X_train,y_train, test_size=0.25)\n",
    "# print(X_train.head())\n",
    "# print(y_train.head())\n",
    "\n",
    "X_train_new = X_train.reset_index(drop=True)\n",
    "y_train_new = y_train.reset_index(drop=True)\n",
    "# print(X_train.head())\n",
    "# print(y_train.head())\n",
    "\n",
    "X_train_new = X_train_new.values\n",
    "y_train_new = y_train_new.values\n",
    "# print(X_train_new)\n",
    "# print(y_train_new)\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k)\n",
    "avg_train_acc,avg_test_acc = 0,0\n",
    "    \n",
    "val_arr = [0.0001,0.001,0.01,0.1,1,10,100,1000,10000,100000]\n",
    "# bestPerformingModel = LogisticRegression(penalty='l2',multi_class='multinomial', solver='lbfgs',C = 1)\n",
    "# bestscore = 0\n",
    "# for val in val_arr:\n",
    "#     logisticRegr = LogisticRegression(penalty='l2',multi_class='multinomial', solver='lbfgs',C = val)\n",
    "#     avgsc = 0\n",
    "#     for train_index, test_index in kf.split(X_train_new):\n",
    "#         X_train_cur, X_test_cur = X_train_new[train_index], X_train_new[test_index]\n",
    "#         y_train_cur, y_test_cur = y_train_new[train_index], y_train_new[test_index]\n",
    "        \n",
    "#         logisticRegr.fit(X_train_cur, y_train_cur)\n",
    "#         sc = logisticRegr.score(X_test_cur, y_test_cur)\n",
    "#         avgsc = avgsc + sc\n",
    "#     avgsc = avgsc/k\n",
    "#     print(avgsc)\n",
    "#     if bestscore < avgsc:\n",
    "#         bestscore = avgsc\n",
    "#         bestPerformingModel = logisticRegr\n",
    "#         print(bestPerformingModel)\n",
    "\n",
    "\n",
    "avgsc_lst,avgsc_train_lst,avgsc_hld_lst = [],[],[]\n",
    "avgsc,avgsc_train,avgsc_hld = 0,0,0\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_new):\n",
    "    X_train_cur, X_test_cur = X_train_new[train_index], X_train_new[test_index]\n",
    "    y_train_cur, y_test_cur = y_train_new[train_index], y_train_new[test_index]\n",
    "    X_train_train, X_val,y_train_train,y_val = train_test_split(X_train_cur,y_train_cur, test_size=0.25,random_state=100)\n",
    "    \n",
    "    bestPerformingModel = LogisticRegression(penalty='l2',multi_class='multinomial', solver='lbfgs',C = 1)\n",
    "    bestscore = 0\n",
    "    for val in val_arr:\n",
    "        clf = LogisticRegression(penalty='l2',multi_class='multinomial', solver='lbfgs',C = val)\n",
    "        clf.fit(X_train_train, y_train_train)\n",
    "        sc = clf.score(X_val, y_val)\n",
    "\n",
    "        if bestscore < sc:\n",
    "            bestscore = sc\n",
    "            bestPerformingModel = clf\n",
    "#                 print(bestPerformingModel)\n",
    "\n",
    "    bscr_train = bestPerformingModel.score(X_train_cur, y_train_cur)\n",
    "    bscr = bestPerformingModel.score(X_test_cur, y_test_cur)\n",
    "    bscr_hld = bestPerformingModel.score(X_test, y_test)\n",
    "\n",
    "    avgsc_train_lst.append(bscr_train)\n",
    "    avgsc_lst.append(bscr)\n",
    "    avgsc_hld_lst.append(bscr_hld)\n",
    "    \n",
    "    avgsc_train = avgsc_train + bscr_train    \n",
    "    avgsc = avgsc + bscr\n",
    "    avgsc_hld = avgsc_hld + bscr_hld\n",
    "\n",
    "    print(bscr_train)\n",
    "    print(bscr)\n",
    "    print(bscr_hld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9349662162162162, 0.9347972972972973, 0.9373310810810811, 0.9364864864864865, 0.9368243243243243]\n",
      "[0.8425675675675676, 0.8243243243243243, 0.8135135135135135, 0.8391891891891892, 0.8344594594594594]\n",
      "[0.8438681793625068, 0.839546191247974, 0.8438681793625068, 0.8411669367909238, 0.8390059427336575]\n",
      "0.9360810810810811\n",
      "0.8308108108108108\n",
      "0.8414910858995137\n",
      "Confusion Matrix: Actual (Row) vs Predicted (Column)\n",
      "[[637   0  23   7  39]\n",
      " [  9 108  13   3  10]\n",
      " [ 18   9 363  25  16]\n",
      " [  5   3  20 126  13]\n",
      " [ 41   4  28  12 319]]\n"
     ]
    }
   ],
   "source": [
    "print(avgsc_train_lst)\n",
    "print(avgsc_lst)\n",
    "print(avgsc_hld_lst)\n",
    "\n",
    "print(avgsc_train/k)\n",
    "print(avgsc/k)\n",
    "print(avgsc_hld/k)\n",
    "\n",
    "y_pred = bestPerformingModel.predict(X_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix: Actual (Row) vs Predicted (Column)')\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Usable directly numeric\n",
      "Class 1: Usable with Extraction\n",
      "Class 2: Usable directly categorical\n",
      "Class 3: Unusable\n",
      "Class 4: Context_specific\n"
     ]
    }
   ],
   "source": [
    "print(\"Class 0: Usable directly numeric\")\n",
    "print(\"Class 1: Usable with Extraction\")\n",
    "print(\"Class 2: Usable directly categorical\")\n",
    "print(\"Class 3: Unusable\")\n",
    "print(\"Class 4: Context_specific\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
